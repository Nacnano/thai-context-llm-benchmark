{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: models/chat-bison-001, Supported Methods: ['generateMessage', 'countMessageTokens']\n",
      "Model: models/text-bison-001, Supported Methods: ['generateText', 'countTextTokens', 'createTunedTextModel']\n",
      "Model: models/embedding-gecko-001, Supported Methods: ['embedText', 'countTextTokens']\n",
      "Model: models/gemini-1.0-pro-vision-latest, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-pro-vision, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-pro-latest, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-pro-001, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-1.5-pro-002, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-1.5-pro, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-latest, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-001, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-1.5-flash-001-tuning, Supported Methods: ['generateContent', 'countTokens', 'createTunedModel']\n",
      "Model: models/gemini-1.5-flash, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-002, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-1.5-flash-8b, Supported Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-8b-001, Supported Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-8b-latest, Supported Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-8b-exp-0827, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-8b-exp-0924, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.5-pro-exp-03-25, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-exp, Supported Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "Model: models/gemini-2.0-flash, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-001, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-exp-image-generation, Supported Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "Model: models/gemini-2.0-flash-lite-001, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-lite, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-lite-preview-02-05, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-lite-preview, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-pro-exp, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-pro-exp-02-05, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-exp-1206, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-thinking-exp-01-21, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-thinking-exp, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-thinking-exp-1219, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/learnlm-1.5-pro-experimental, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemma-3-1b-it, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemma-3-4b-it, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemma-3-12b-it, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemma-3-27b-it, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/embedding-001, Supported Methods: ['embedContent']\n",
      "Model: models/text-embedding-004, Supported Methods: ['embedContent']\n",
      "Model: models/gemini-embedding-exp-03-07, Supported Methods: ['embedContent']\n",
      "Model: models/gemini-embedding-exp, Supported Methods: ['embedContent']\n",
      "Model: models/aqa, Supported Methods: ['generateAnswer']\n",
      "Model: models/imagen-3.0-generate-002, Supported Methods: ['predict']\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure API\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in .env file\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# List available models\n",
    "for model in genai.list_models():\n",
    "    print(f\"Model: {model.name}, Supported Methods: {model.supported_generation_methods}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene graph generation for thailand_12006.jpeg took 8.18 seconds\n",
      "GQA question generation for thailand_12006.jpeg took 7.82 seconds\n",
      "Scene graph saved to output\\thailand_12006_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12006_gqa_questions.json\n",
      "Scene graph generation for thailand_12007.jpeg took 7.01 seconds\n",
      "GQA question generation for thailand_12007.jpeg took 7.59 seconds\n",
      "Scene graph saved to output\\thailand_12007_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12007_gqa_questions.json\n",
      "Scene graph generation for thailand_12008.jpeg took 6.87 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 200\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# Run the pipeline\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 200\u001b[0m     \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 192\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[1;34m(image_folder, output_folder)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Generate GQA questions\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m gqa_questions \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_gqa_questions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscene_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# Save both outputs\u001b[39;00m\n\u001b[0;32m    195\u001b[0m output_path_base \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 121\u001b[0m, in \u001b[0;36mgenerate_gqa_questions\u001b[1;34m(model, scene_graph, image, image_name)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 121\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmime_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage/jpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_base64\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    127\u001b[0m     duration \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:867\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    866\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\grpc\\_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    270\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\grpc\\_interceptor.py:329\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m--> 329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interceptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mresult(), call\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\transports\\grpc.py:79\u001b[0m, in \u001b[0;36m_LoggingClientInterceptor.intercept_unary_unary\u001b[1;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[0;32m     64\u001b[0m     grpc_request \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayload\u001b[39m\u001b[38;5;124m\"\u001b[39m: request_payload,\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequestMethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrpc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[0;32m     68\u001b[0m     }\n\u001b[0;32m     69\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     71\u001b[0m         extra\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m         },\n\u001b[0;32m     77\u001b[0m     )\n\u001b[1;32m---> 79\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     response_metadata \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtrailing_metadata()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\grpc\\_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[1;34m(new_details, request)\u001b[0m\n\u001b[0;32m    306\u001b[0m (\n\u001b[0;32m    307\u001b[0m     new_method,\n\u001b[0;32m    308\u001b[0m     new_timeout,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    312\u001b[0m     new_compression,\n\u001b[0;32m    313\u001b[0m ) \u001b[38;5;241m=\u001b[39m _unwrap_client_call_details(new_details, client_call_details)\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\grpc\\_channel.py:1195\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_call\u001b[39m(\n\u001b[0;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1185\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1190\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1191\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, grpc\u001b[38;5;241m.\u001b[39mCall]:\n\u001b[0;32m   1192\u001b[0m     (\n\u001b[0;32m   1193\u001b[0m         state,\n\u001b[0;32m   1194\u001b[0m         call,\n\u001b[1;32m-> 1195\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\grpc\\_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[0;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[0;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[1;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from google.generativeai import GenerativeModel\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Step 1: Setup API Configuration\n",
    "def configure_api():\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"GEMINI_API_KEY not found in .env file\")\n",
    "    genai.configure(api_key=api_key)\n",
    "    return GenerativeModel('gemini-2.0-flash')  # Adjust if needed\n",
    "\n",
    "# Step 2: Load and Process Image\n",
    "def load_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        width, height = img.size\n",
    "        return img, width, height\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Step 3: Convert Image to Base64\n",
    "def image_to_base64(image):\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "# Step 4: Generate Scene Graph using Gemini API\n",
    "def generate_scene_graph(model, image, width, height, image_name):\n",
    "    prompt = \"\"\"\n",
    "    Generate a detailed image scene graph of this image using the Thai language based on this template\n",
    "\n",
    "    {\n",
    "       \"width\": 640,\n",
    "       \"height\": 480,\n",
    "       \"location\": \"living room\",\n",
    "       \"weather\": \"none\",\n",
    "       \"objects\": {\n",
    "           \"271881\": {\n",
    "               \"name\": \"chair\",\n",
    "               \"x\": 220,\n",
    "               \"y\": 310,\n",
    "               \"w\": 50,\n",
    "               \"h\": 80,\n",
    "               \"attributes\": [\"brown\", \"wooden\", \"small\"],\n",
    "               \"relations\": {\n",
    "                   \"32452\": {\n",
    "                       \"name\": \"on\",\n",
    "                       \"object\": \"275312\"\n",
    "                   },\n",
    "                   \"32453\": {\n",
    "                       \"name\": \"near\",\n",
    "                       \"object\": \"279472\"\n",
    "                   }\n",
    "               }\n",
    "           }\n",
    "       }\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    image_base64 = image_to_base64(image)\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = model.generate_content([\n",
    "            prompt,\n",
    "            {\"mime_type\": \"image/jpeg\", \"data\": image_base64}\n",
    "        ])\n",
    "        \n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        print(f\"Scene graph generation for {image_name} took {duration:.2f} seconds\")\n",
    "        \n",
    "        raw_response = response.text.strip()\n",
    "        if not raw_response:\n",
    "            print(f\"Error: Empty response for scene graph {image_name}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            raw_response = raw_response.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "            scene_graph = json.loads(raw_response)\n",
    "            return scene_graph\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error for scene graph {image_name}: {e}\")\n",
    "            print(f\"Raw response length: {len(raw_response)}\")\n",
    "            print(f\"Raw response (first 100 chars): {raw_response[:100]}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating scene graph for {image_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 5: Generate GQA Questions\n",
    "def generate_gqa_questions(model, scene_graph, image, image_name):\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following scene graph, generate 20 GQA-style questions in English with this format:\n",
    "    \n",
    "        question: Is there a red apple on the table?,\n",
    "        answer: no,\n",
    "        fullAnswer: No, there is an apple but it is green.\n",
    "    but in json format\n",
    "    \n",
    "    Scene graph: {json.dumps(scene_graph, ensure_ascii=False)}\n",
    "    \n",
    "    Return the questions as a JSON array.\n",
    "    \"\"\"\n",
    "    \n",
    "    image_base64 = image_to_base64(image)\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = model.generate_content([\n",
    "            prompt,\n",
    "            {\"mime_type\": \"image/jpeg\", \"data\": image_base64}\n",
    "        ])\n",
    "        \n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        print(f\"GQA question generation for {image_name} took {duration:.2f} seconds\")\n",
    "        \n",
    "        raw_response = response.text.strip()\n",
    "        if not raw_response:\n",
    "            print(f\"Error: Empty response for GQA questions {image_name}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            raw_response = raw_response.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "            gqa_questions = json.loads(raw_response)\n",
    "            return gqa_questions\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error for GQA questions {image_name}: {e}\")\n",
    "            print(f\"Raw response length: {len(raw_response)}\")\n",
    "            print(f\"Raw response (first 100 chars): {raw_response[:100]}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating GQA questions for {image_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 6: Save Scene Graph and GQA Questions\n",
    "def save_output(scene_graph, gqa_questions, output_path_base):\n",
    "    try:\n",
    "        # Save scene graph\n",
    "        scene_graph_path = f\"{output_path_base}_scene_graph.json\"\n",
    "        with open(scene_graph_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(scene_graph, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Scene graph saved to {scene_graph_path}\")\n",
    "        \n",
    "        # Save GQA questions\n",
    "        if gqa_questions:\n",
    "            gqa_path = f\"{output_path_base}_gqa_questions.json\"\n",
    "            with open(gqa_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(gqa_questions, f, ensure_ascii=False, indent=4)\n",
    "            print(f\"GQA questions saved to {gqa_path}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving output to {output_path_base}: {e}\")\n",
    "\n",
    "# Main Pipeline\n",
    "def run_pipeline(image_folder='data\\\\sea-vqa\\\\thailand', output_folder='output'):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        model = configure_api()\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return\n",
    "    \n",
    "    for image_name in os.listdir(image_folder):\n",
    "        if image_name.lower().endswith('.jpeg'):\n",
    "            image_path = os.path.join(image_folder, image_name)\n",
    "            img, width, height = load_image(image_path)\n",
    "            \n",
    "            if img is None:\n",
    "                continue\n",
    "                \n",
    "            # Generate scene graph\n",
    "            scene_graph = generate_scene_graph(model, img, width, height, image_name)\n",
    "            \n",
    "            if scene_graph is None:\n",
    "                continue\n",
    "                \n",
    "            # Generate GQA questions\n",
    "            gqa_questions = generate_gqa_questions(model, scene_graph, img, image_name)\n",
    "            \n",
    "            # Save both outputs\n",
    "            output_path_base = os.path.join(output_folder, f\"{image_name.split('.')[0]}\")\n",
    "            save_output(scene_graph, gqa_questions, output_path_base)\n",
    "\n",
    "# Run the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
