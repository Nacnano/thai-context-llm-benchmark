{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: models/chat-bison-001, Supported Methods: ['generateMessage', 'countMessageTokens']\n",
      "Model: models/text-bison-001, Supported Methods: ['generateText', 'countTextTokens', 'createTunedTextModel']\n",
      "Model: models/embedding-gecko-001, Supported Methods: ['embedText', 'countTextTokens']\n",
      "Model: models/gemini-1.0-pro-vision-latest, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-pro-vision, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-pro-latest, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-pro-001, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-1.5-pro-002, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-1.5-pro, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-latest, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-001, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-1.5-flash-001-tuning, Supported Methods: ['generateContent', 'countTokens', 'createTunedModel']\n",
      "Model: models/gemini-1.5-flash, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-002, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-1.5-flash-8b, Supported Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-8b-001, Supported Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-8b-latest, Supported Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-8b-exp-0827, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-8b-exp-0924, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.5-pro-exp-03-25, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-2.5-pro-preview-03-25, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-2.5-flash-preview-04-17, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-2.5-flash-preview-04-17-thinking, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-2.5-pro-preview-05-06, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-2.0-flash-exp, Supported Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "Model: models/gemini-2.0-flash, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-2.0-flash-001, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-2.0-flash-exp-image-generation, Supported Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "Model: models/gemini-2.0-flash-lite-001, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-2.0-flash-lite, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-2.0-flash-preview-image-generation, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-lite-preview-02-05, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-2.0-flash-lite-preview, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-2.0-pro-exp, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-2.0-pro-exp-02-05, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-exp-1206, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-2.0-flash-thinking-exp-01-21, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-2.0-flash-thinking-exp, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-2.0-flash-thinking-exp-1219, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/learnlm-1.5-pro-experimental, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/learnlm-2.0-flash-experimental, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemma-3-1b-it, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemma-3-4b-it, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemma-3-12b-it, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemma-3-27b-it, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/embedding-001, Supported Methods: ['embedContent']\n",
      "Model: models/text-embedding-004, Supported Methods: ['embedContent']\n",
      "Model: models/gemini-embedding-exp-03-07, Supported Methods: ['embedContent', 'countTextTokens']\n",
      "Model: models/gemini-embedding-exp, Supported Methods: ['embedContent', 'countTextTokens']\n",
      "Model: models/aqa, Supported Methods: ['generateAnswer']\n",
      "Model: models/imagen-3.0-generate-002, Supported Methods: ['predict']\n",
      "Model: models/gemini-2.0-flash-live-001, Supported Methods: ['bidiGenerateContent', 'countTokens']\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure API\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in .env file\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# List available models\n",
    "for model in genai.list_models():\n",
    "    print(f\"Model: {model.name}, Supported Methods: {model.supported_generation_methods}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene graph generation for thailand_12006.jpeg took 10.61 seconds\n",
      "GQA question generation for thailand_12006.jpeg took 10.72 seconds\n",
      "Scene graph saved to output\\thailand_12006_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12006_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12007.jpeg took 9.16 seconds\n",
      "GQA question generation for thailand_12007.jpeg took 8.44 seconds\n",
      "Scene graph saved to output\\thailand_12007_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12007_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12008.jpeg took 6.87 seconds\n",
      "GQA question generation for thailand_12008.jpeg took 8.12 seconds\n",
      "Scene graph saved to output\\thailand_12008_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12008_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12009.jpeg took 6.10 seconds\n",
      "GQA question generation for thailand_12009.jpeg took 7.88 seconds\n",
      "Scene graph saved to output\\thailand_12009_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12009_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12010.jpeg took 6.76 seconds\n",
      "GQA question generation for thailand_12010.jpeg took 8.17 seconds\n",
      "Scene graph saved to output\\thailand_12010_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12010_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12011.jpeg took 6.20 seconds\n",
      "GQA question generation for thailand_12011.jpeg took 7.18 seconds\n",
      "Scene graph saved to output\\thailand_12011_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12011_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12012.jpeg took 5.88 seconds\n",
      "GQA question generation for thailand_12012.jpeg took 8.36 seconds\n",
      "Scene graph saved to output\\thailand_12012_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12012_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12013.jpeg took 5.59 seconds\n",
      "GQA question generation for thailand_12013.jpeg took 6.82 seconds\n",
      "Scene graph saved to output\\thailand_12013_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12013_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12014.jpeg took 3.84 seconds\n",
      "GQA question generation for thailand_12014.jpeg took 7.16 seconds\n",
      "Scene graph saved to output\\thailand_12014_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12014_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12015.jpeg took 5.74 seconds\n",
      "JSON parsing error for scene graph thailand_12015.jpeg: Expecting value: line 1 column 1 (char 0)\n",
      "Raw response length: 1909\n",
      "Raw response (first 100 chars): ขออภัย ฉันไม่สามารถระบุตำแหน่งที่แน่นอนของ \"living room\" หรือ \"weather\" ได้เนื่องจากข้อมูลนั้นไม่ได้\n",
      "Scene graph generation for thailand_12429.jpeg took 5.68 seconds\n",
      "GQA question generation for thailand_12429.jpeg took 7.55 seconds\n",
      "Scene graph saved to output\\thailand_12429_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12429_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12430.jpeg took 5.07 seconds\n",
      "GQA question generation for thailand_12430.jpeg took 7.01 seconds\n",
      "Scene graph saved to output\\thailand_12430_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12430_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12431.jpeg took 8.05 seconds\n",
      "GQA question generation for thailand_12431.jpeg took 8.41 seconds\n",
      "Scene graph saved to output\\thailand_12431_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12431_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12432.jpeg took 5.28 seconds\n",
      "GQA question generation for thailand_12432.jpeg took 8.49 seconds\n",
      "Scene graph saved to output\\thailand_12432_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12432_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12433.jpeg took 5.28 seconds\n",
      "GQA question generation for thailand_12433.jpeg took 7.54 seconds\n",
      "Scene graph saved to output\\thailand_12433_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12433_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12434.jpeg took 6.12 seconds\n",
      "GQA question generation for thailand_12434.jpeg took 6.53 seconds\n",
      "Scene graph saved to output\\thailand_12434_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12434_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12435.jpeg took 6.33 seconds\n",
      "GQA question generation for thailand_12435.jpeg took 7.47 seconds\n",
      "Scene graph saved to output\\thailand_12435_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12435_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12436.jpeg took 7.45 seconds\n",
      "GQA question generation for thailand_12436.jpeg took 8.34 seconds\n",
      "Scene graph saved to output\\thailand_12436_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12436_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12437.jpeg took 7.03 seconds\n",
      "GQA question generation for thailand_12437.jpeg took 7.76 seconds\n",
      "Scene graph saved to output\\thailand_12437_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12437_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_12438.jpeg took 6.18 seconds\n",
      "GQA question generation for thailand_12438.jpeg took 9.77 seconds\n",
      "Scene graph saved to output\\thailand_12438_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12438_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_14180.jpeg took 8.47 seconds\n",
      "GQA question generation for thailand_14180.jpeg took 13.91 seconds\n",
      "Scene graph saved to output\\thailand_14180_scene_graph.json\n",
      "GQA questions saved to output\\thailand_14180_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_14181.jpeg took 5.64 seconds\n",
      "GQA question generation for thailand_14181.jpeg took 8.35 seconds\n",
      "Scene graph saved to output\\thailand_14181_scene_graph.json\n",
      "GQA questions saved to output\\thailand_14181_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_14182.jpeg took 7.59 seconds\n",
      "GQA question generation for thailand_14182.jpeg took 8.14 seconds\n",
      "Scene graph saved to output\\thailand_14182_scene_graph.json\n",
      "GQA questions saved to output\\thailand_14182_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_14183.jpeg took 7.11 seconds\n",
      "GQA question generation for thailand_14183.jpeg took 8.15 seconds\n",
      "Scene graph saved to output\\thailand_14183_scene_graph.json\n",
      "GQA questions saved to output\\thailand_14183_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_14184.jpeg took 3.94 seconds\n",
      "JSON parsing error for scene graph thailand_14184.jpeg: Expecting value: line 1 column 1 (char 0)\n",
      "Raw response length: 76\n",
      "Raw response (first 100 chars): ขออภัย ฉันไม่สามารถตรวจพบรายละเอียดของภาพนั้นได้มากพอที่จะสร้างกราฟฉากภาพได้\n",
      "Scene graph generation for thailand_14186.jpeg took 10.96 seconds\n",
      "GQA question generation for thailand_14186.jpeg took 7.51 seconds\n",
      "Scene graph saved to output\\thailand_14186_scene_graph.json\n",
      "GQA questions saved to output\\thailand_14186_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_14187.jpeg took 4.63 seconds\n",
      "GQA question generation for thailand_14187.jpeg took 7.57 seconds\n",
      "Scene graph saved to output\\thailand_14187_scene_graph.json\n",
      "GQA questions saved to output\\thailand_14187_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_14188.jpeg took 8.34 seconds\n",
      "GQA question generation for thailand_14188.jpeg took 8.59 seconds\n",
      "Scene graph saved to output\\thailand_14188_scene_graph.json\n",
      "GQA questions saved to output\\thailand_14188_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_14189.jpeg took 4.97 seconds\n",
      "GQA question generation for thailand_14189.jpeg took 7.51 seconds\n",
      "Scene graph saved to output\\thailand_14189_scene_graph.json\n",
      "GQA questions saved to output\\thailand_14189_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_15308.jpeg took 5.50 seconds\n",
      "GQA question generation for thailand_15308.jpeg took 6.57 seconds\n",
      "Scene graph saved to output\\thailand_15308_scene_graph.json\n",
      "GQA questions saved to output\\thailand_15308_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_15309.jpeg took 5.99 seconds\n",
      "GQA question generation for thailand_15309.jpeg took 10.72 seconds\n",
      "Scene graph saved to output\\thailand_15309_scene_graph.json\n",
      "GQA questions saved to output\\thailand_15309_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_15310.jpeg took 4.32 seconds\n",
      "GQA question generation for thailand_15310.jpeg took 6.28 seconds\n",
      "Scene graph saved to output\\thailand_15310_scene_graph.json\n",
      "GQA questions saved to output\\thailand_15310_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_15311.jpeg took 7.46 seconds\n",
      "GQA question generation for thailand_15311.jpeg took 7.26 seconds\n",
      "Scene graph saved to output\\thailand_15311_scene_graph.json\n",
      "GQA questions saved to output\\thailand_15311_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_15312.jpeg took 5.58 seconds\n",
      "GQA question generation for thailand_15312.jpeg took 6.41 seconds\n",
      "Scene graph saved to output\\thailand_15312_scene_graph.json\n",
      "GQA questions saved to output\\thailand_15312_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_15313.jpeg took 6.71 seconds\n",
      "GQA question generation for thailand_15313.jpeg took 9.13 seconds\n",
      "Scene graph saved to output\\thailand_15313_scene_graph.json\n",
      "GQA questions saved to output\\thailand_15313_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_15314.jpeg took 6.34 seconds\n",
      "GQA question generation for thailand_15314.jpeg took 8.35 seconds\n",
      "Scene graph saved to output\\thailand_15314_scene_graph.json\n",
      "GQA questions saved to output\\thailand_15314_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_15315.jpeg took 1.60 seconds\n",
      "JSON parsing error for scene graph thailand_15315.jpeg: Expecting value: line 1 column 1 (char 0)\n",
      "Raw response length: 102\n",
      "Raw response (first 100 chars): ขออภัย ฉันไม่สามารถให้รายละเอียดได้เนื่องจากไม่มีข้อมูลเกี่ยวกับสถานที่ สภาพอากาศ และคุณสมบัติของวัต\n",
      "Scene graph generation for thailand_15316.jpeg took 9.29 seconds\n",
      "GQA question generation for thailand_15316.jpeg took 7.94 seconds\n",
      "Scene graph saved to output\\thailand_15316_scene_graph.json\n",
      "GQA questions saved to output\\thailand_15316_gqa_questions_thai.json\n",
      "Scene graph generation for thailand_15317.jpeg took 8.51 seconds\n",
      "GQA question generation for thailand_15317.jpeg took 9.45 seconds\n",
      "Scene graph saved to output\\thailand_15317_scene_graph.json\n",
      "GQA questions saved to output\\thailand_15317_gqa_questions_thai.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from google.generativeai import GenerativeModel\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Step 1: Setup API Configuration\n",
    "def configure_api():\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"GEMINI_API_KEY not found in .env file\")\n",
    "    genai.configure(api_key=api_key)\n",
    "    return GenerativeModel('gemini-2.0-flash')  # Adjust if needed\n",
    "\n",
    "# Step 2: Load and Process Image\n",
    "def load_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        width, height = img.size\n",
    "        return img, width, height\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Step 3: Convert Image to Base64\n",
    "def image_to_base64(image):\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "# Step 4: Generate Scene Graph using Gemini API\n",
    "def generate_scene_graph(model, image, width, height, image_name):\n",
    "    prompt = \"\"\"\n",
    "    Generate a detailed image scene graph of this image using the Thai language based on this template\n",
    "    Please be as detailed as possible and include all objects, their attributes, and relations.\n",
    "    Please focus on Thai context and culture.\n",
    "    {\n",
    "       \"width\": 640,\n",
    "       \"height\": 480,\n",
    "       \"location\": \"living room\",\n",
    "       \"weather\": \"none\",\n",
    "       \"objects\": {\n",
    "           \"271881\": {\n",
    "               \"name\": \"chair\",\n",
    "               \"x\": 220,\n",
    "               \"y\": 310,\n",
    "               \"w\": 50,\n",
    "               \"h\": 80,\n",
    "               \"attributes\": [\"brown\", \"wooden\", \"small\"],\n",
    "               \"relations\": {\n",
    "                   \"32452\": {\n",
    "                       \"name\": \"on\",\n",
    "                       \"object\": \"275312\"\n",
    "                   },\n",
    "                   \"32453\": {\n",
    "                       \"name\": \"near\",\n",
    "                       \"object\": \"279472\"\n",
    "                   }\n",
    "               }\n",
    "           }\n",
    "       }\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    image_base64 = image_to_base64(image)\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = model.generate_content([\n",
    "            prompt,\n",
    "            {\"mime_type\": \"image/jpeg\", \"data\": image_base64}\n",
    "        ])\n",
    "        \n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        print(f\"Scene graph generation for {image_name} took {duration:.2f} seconds\")\n",
    "        \n",
    "        raw_response = response.text.strip()\n",
    "        if not raw_response:\n",
    "            print(f\"Error: Empty response for scene graph {image_name}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            raw_response = raw_response.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "            scene_graph = json.loads(raw_response)\n",
    "            return scene_graph\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error for scene graph {image_name}: {e}\")\n",
    "            print(f\"Raw response length: {len(raw_response)}\")\n",
    "            print(f\"Raw response (first 100 chars): {raw_response[:100]}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating scene graph for {image_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 5: Generate GQA Questions\n",
    "def generate_gqa_questions(model, scene_graph, image, image_name):\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following scene graph, generate 20 GQA-style questions in Thai with this format:\n",
    "        question: \n",
    "        shortAnswer:\n",
    "        fullAnswer:\n",
    "    in json format\n",
    "    \n",
    "    Scene graph: {json.dumps(scene_graph, ensure_ascii=False)}\n",
    "    \n",
    "    Return the questions as a JSON array.\n",
    "    \"\"\"\n",
    "    \n",
    "    image_base64 = image_to_base64(image)\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = model.generate_content([\n",
    "            prompt,\n",
    "            {\"mime_type\": \"image/jpeg\", \"data\": image_base64}\n",
    "        ])\n",
    "        \n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        print(f\"GQA question generation for {image_name} took {duration:.2f} seconds\")\n",
    "        \n",
    "        raw_response = response.text.strip()\n",
    "        if not raw_response:\n",
    "            print(f\"Error: Empty response for GQA questions {image_name}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            raw_response = raw_response.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "            gqa_questions = json.loads(raw_response)\n",
    "            return gqa_questions\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error for GQA questions {image_name}: {e}\")\n",
    "            print(f\"Raw response length: {len(raw_response)}\")\n",
    "            print(f\"Raw response (first 100 chars): {raw_response[:100]}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating GQA questions for {image_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 6: Save Scene Graph and GQA Questions\n",
    "def save_output(scene_graph, gqa_questions, output_path_base):\n",
    "    try:\n",
    "        # Save scene graph\n",
    "        scene_graph_path = f\"{output_path_base}_scene_graph.json\"\n",
    "        with open(scene_graph_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(scene_graph, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Scene graph saved to {scene_graph_path}\")\n",
    "        \n",
    "        # Save GQA questions\n",
    "        if gqa_questions:\n",
    "            gqa_path = f\"{output_path_base}_gqa_questions_thai.json\"\n",
    "            with open(gqa_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(gqa_questions, f, ensure_ascii=False, indent=4)\n",
    "            print(f\"GQA questions saved to {gqa_path}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving output to {output_path_base}: {e}\")\n",
    "\n",
    "# Main Pipeline\n",
    "def run_pipeline(image_folder='data\\\\sea-vqa\\\\thailand', output_folder='output'):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        model = configure_api()\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return\n",
    "    \n",
    "    for image_name in os.listdir(image_folder):\n",
    "        if image_name.lower().endswith('.jpeg'):\n",
    "            image_path = os.path.join(image_folder, image_name)\n",
    "            img, width, height = load_image(image_path)\n",
    "            \n",
    "            if img is None:\n",
    "                continue\n",
    "                \n",
    "            # Generate scene graph\n",
    "            scene_graph = generate_scene_graph(model, img, width, height, image_name)\n",
    "            \n",
    "            if scene_graph is None:\n",
    "                continue\n",
    "                \n",
    "            # Generate GQA questions\n",
    "            gqa_questions = generate_gqa_questions(model, scene_graph, img, image_name)\n",
    "            \n",
    "            # Save both outputs\n",
    "            output_path_base = os.path.join(output_folder, f\"{image_name.split('.')[0]}\")\n",
    "            save_output(scene_graph, gqa_questions, output_path_base)\n",
    "\n",
    "# Run the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
