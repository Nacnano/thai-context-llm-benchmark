{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: models/chat-bison-001, Supported Methods: ['generateMessage', 'countMessageTokens']\n",
      "Model: models/text-bison-001, Supported Methods: ['generateText', 'countTextTokens', 'createTunedTextModel']\n",
      "Model: models/embedding-gecko-001, Supported Methods: ['embedText', 'countTextTokens']\n",
      "Model: models/gemini-1.0-pro-vision-latest, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-pro-vision, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-pro-latest, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-pro-001, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-1.5-pro-002, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-1.5-pro, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-latest, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-001, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-1.5-flash-001-tuning, Supported Methods: ['generateContent', 'countTokens', 'createTunedModel']\n",
      "Model: models/gemini-1.5-flash, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-002, Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "Model: models/gemini-1.5-flash-8b, Supported Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-8b-001, Supported Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-8b-latest, Supported Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-8b-exp-0827, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-1.5-flash-8b-exp-0924, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.5-pro-exp-03-25, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-exp, Supported Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "Model: models/gemini-2.0-flash, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-001, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-exp-image-generation, Supported Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "Model: models/gemini-2.0-flash-lite-001, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-lite, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-lite-preview-02-05, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-lite-preview, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-pro-exp, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-pro-exp-02-05, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-exp-1206, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-thinking-exp-01-21, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-thinking-exp, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemini-2.0-flash-thinking-exp-1219, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/learnlm-1.5-pro-experimental, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemma-3-1b-it, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemma-3-4b-it, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemma-3-12b-it, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/gemma-3-27b-it, Supported Methods: ['generateContent', 'countTokens']\n",
      "Model: models/embedding-001, Supported Methods: ['embedContent']\n",
      "Model: models/text-embedding-004, Supported Methods: ['embedContent']\n",
      "Model: models/gemini-embedding-exp-03-07, Supported Methods: ['embedContent']\n",
      "Model: models/gemini-embedding-exp, Supported Methods: ['embedContent']\n",
      "Model: models/aqa, Supported Methods: ['generateAnswer']\n",
      "Model: models/imagen-3.0-generate-002, Supported Methods: ['predict']\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure API\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in .env file\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# List available models\n",
    "for model in genai.list_models():\n",
    "    print(f\"Model: {model.name}, Supported Methods: {model.supported_generation_methods}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene graph generation for thailand_12006.jpeg took 8.18 seconds\n",
      "GQA question generation for thailand_12006.jpeg took 7.82 seconds\n",
      "Scene graph saved to output\\thailand_12006_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12006_gqa_questions.json\n",
      "Scene graph generation for thailand_12007.jpeg took 7.01 seconds\n",
      "GQA question generation for thailand_12007.jpeg took 7.59 seconds\n",
      "Scene graph saved to output\\thailand_12007_scene_graph.json\n",
      "GQA questions saved to output\\thailand_12007_gqa_questions.json\n",
      "Scene graph generation for thailand_12008.jpeg took 6.87 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from google.generativeai import GenerativeModel\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Step 1: Setup API Configuration\n",
    "def configure_api():\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"GEMINI_API_KEY not found in .env file\")\n",
    "    genai.configure(api_key=api_key)\n",
    "    return GenerativeModel('gemini-2.0-flash')  # Adjust if needed\n",
    "\n",
    "# Step 2: Load and Process Image\n",
    "def load_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        width, height = img.size\n",
    "        return img, width, height\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Step 3: Convert Image to Base64\n",
    "def image_to_base64(image):\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "# Step 4: Generate Scene Graph using Gemini API\n",
    "def generate_scene_graph(model, image, width, height, image_name):\n",
    "    prompt = \"\"\"\n",
    "    Generate a detailed image scene graph of this image using the Thai language based on this template\n",
    "\n",
    "    {\n",
    "       \"width\": 640,\n",
    "       \"height\": 480,\n",
    "       \"location\": \"living room\",\n",
    "       \"weather\": \"none\",\n",
    "       \"objects\": {\n",
    "           \"271881\": {\n",
    "               \"name\": \"chair\",\n",
    "               \"x\": 220,\n",
    "               \"y\": 310,\n",
    "               \"w\": 50,\n",
    "               \"h\": 80,\n",
    "               \"attributes\": [\"brown\", \"wooden\", \"small\"],\n",
    "               \"relations\": {\n",
    "                   \"32452\": {\n",
    "                       \"name\": \"on\",\n",
    "                       \"object\": \"275312\"\n",
    "                   },\n",
    "                   \"32453\": {\n",
    "                       \"name\": \"near\",\n",
    "                       \"object\": \"279472\"\n",
    "                   }\n",
    "               }\n",
    "           }\n",
    "       }\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    image_base64 = image_to_base64(image)\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = model.generate_content([\n",
    "            prompt,\n",
    "            {\"mime_type\": \"image/jpeg\", \"data\": image_base64}\n",
    "        ])\n",
    "        \n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        print(f\"Scene graph generation for {image_name} took {duration:.2f} seconds\")\n",
    "        \n",
    "        raw_response = response.text.strip()\n",
    "        if not raw_response:\n",
    "            print(f\"Error: Empty response for scene graph {image_name}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            raw_response = raw_response.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "            scene_graph = json.loads(raw_response)\n",
    "            return scene_graph\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error for scene graph {image_name}: {e}\")\n",
    "            print(f\"Raw response length: {len(raw_response)}\")\n",
    "            print(f\"Raw response (first 100 chars): {raw_response[:100]}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating scene graph for {image_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 5: Generate GQA Questions\n",
    "def generate_gqa_questions(model, scene_graph, image, image_name):\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following scene graph, generate 20 GQA-style questions in English with this format:\n",
    "    \n",
    "        question: Is there a red apple on the table?,\n",
    "        answer: no,\n",
    "        fullAnswer: No, there is an apple but it is green.\n",
    "    but in json format\n",
    "    \n",
    "    Scene graph: {json.dumps(scene_graph, ensure_ascii=False)}\n",
    "    \n",
    "    Return the questions as a JSON array.\n",
    "    \"\"\"\n",
    "    \n",
    "    image_base64 = image_to_base64(image)\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = model.generate_content([\n",
    "            prompt,\n",
    "            {\"mime_type\": \"image/jpeg\", \"data\": image_base64}\n",
    "        ])\n",
    "        \n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        print(f\"GQA question generation for {image_name} took {duration:.2f} seconds\")\n",
    "        \n",
    "        raw_response = response.text.strip()\n",
    "        if not raw_response:\n",
    "            print(f\"Error: Empty response for GQA questions {image_name}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            raw_response = raw_response.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "            gqa_questions = json.loads(raw_response)\n",
    "            return gqa_questions\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error for GQA questions {image_name}: {e}\")\n",
    "            print(f\"Raw response length: {len(raw_response)}\")\n",
    "            print(f\"Raw response (first 100 chars): {raw_response[:100]}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating GQA questions for {image_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 6: Save Scene Graph and GQA Questions\n",
    "def save_output(scene_graph, gqa_questions, output_path_base):\n",
    "    try:\n",
    "        # Save scene graph\n",
    "        scene_graph_path = f\"{output_path_base}_scene_graph.json\"\n",
    "        with open(scene_graph_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(scene_graph, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Scene graph saved to {scene_graph_path}\")\n",
    "        \n",
    "        # Save GQA questions\n",
    "        if gqa_questions:\n",
    "            gqa_path = f\"{output_path_base}_gqa_questions.json\"\n",
    "            with open(gqa_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(gqa_questions, f, ensure_ascii=False, indent=4)\n",
    "            print(f\"GQA questions saved to {gqa_path}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving output to {output_path_base}: {e}\")\n",
    "\n",
    "# Main Pipeline\n",
    "def run_pipeline(image_folder='data\\\\sea-vqa\\\\thailand', output_folder='output'):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        model = configure_api()\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return\n",
    "    \n",
    "    for image_name in os.listdir(image_folder):\n",
    "        if image_name.lower().endswith('.jpeg'):\n",
    "            image_path = os.path.join(image_folder, image_name)\n",
    "            img, width, height = load_image(image_path)\n",
    "            \n",
    "            if img is None:\n",
    "                continue\n",
    "                \n",
    "            # Generate scene graph\n",
    "            scene_graph = generate_scene_graph(model, img, width, height, image_name)\n",
    "            \n",
    "            if scene_graph is None:\n",
    "                continue\n",
    "                \n",
    "            # Generate GQA questions\n",
    "            gqa_questions = generate_gqa_questions(model, scene_graph, img, image_name)\n",
    "            \n",
    "            # Save both outputs\n",
    "            output_path_base = os.path.join(output_folder, f\"{image_name.split('.')[0]}\")\n",
    "            save_output(scene_graph, gqa_questions, output_path_base)\n",
    "\n",
    "# Run the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
